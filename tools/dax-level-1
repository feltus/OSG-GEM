#!/usr/bin/env python

from __future__ import division

from AutoADAG import *
from Pegasus.DAX3 import *
import sys
import math
import os
import re
import subprocess

base_dir = os.getcwd()

run_id = sys.argv[1]
run_dir = sys.argv[2]    
data_dir = sys.argv[3]

def main():
    # Create a abstract dag
    dax = AutoADAG("tophat")

    # email notificiations for when the state of the workflow changes
    dax.invoke('all',  base_dir + "/email-notify")
    
    # Add executables to the DAX-level replica catalog
    for exe_name in os.listdir("./tools/"):
        exe = Executable(name=exe_name, arch="x86_64", installed=False)
        exe.addPFN(PFN("file://" + base_dir + "/tools/" + exe_name, "local"))
        dax.addExecutable(exe)

    subdax_file = File("level-2.dax")
    subdax_file.addPFN(PFN("file://%s/workflow/level-2.dax" % (run_dir), "local"))
    dax.addFile(subdax_file) 

    # set up split job
    j1 = Job(name="prepare-inputs")
    j1.addArguments(base_dir, base_dir + "/inputs", data_dir)
    j1.addProfile(Profile("hints", "execution.site", "local"))
    dax.addJob(j1)

    # generate sub workflow
    j2 = Job(name="dax-level-2")
    j2.addArguments(run_id, base_dir, run_dir)
    j2.addProfile(Profile("hints", "execution.site", "local"))
    dax.addJob(j2)
    dax.depends(parent=j1, child=j2)

    # sub workflow job
    j3 = DAX("level-2.dax")
    j3.addArguments("-Dpegasus.catalog.site.file=%s/sites.xml" % (base_dir),
                    "--sites", "condorpool",
                    "--staging-site", "stash",
                    "--output-site", "local",
                    "--basename", "level-2",
                    "--force",
                    "--cleanup", "none")
    j3.uses(subdax_file, link=Link.INPUT)
    dax.addDAX(j3)
    dax.depends(parent=j2, child=j3)
    
    # Write the DAX to stdout
    f = open("dax.xml", "w")
    dax.writeXML(f)
    f.close()

main()

